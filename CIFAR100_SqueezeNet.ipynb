{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR100_SqueezeNet.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMXNf+1VJmj9UiKb13SLyma",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aborundiya/CNN/blob/master/CIFAR100_SqueezeNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Nb5IiFcVI8r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import copy \n",
        "import torch \n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn \n",
        "import torch.optim as optim \n",
        "from torchvision import models\n",
        "import matplotlib.pyplot as plt "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zxwGUfXWHFa",
        "colab_type": "text"
      },
      "source": [
        "#Check for GPU "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duZiWqthV-fr",
        "colab_type": "code",
        "outputId": "aa5d7106-bb74-4cd7-86a4-5e3377f8a3d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "device = torch.device('cuda:0'if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npL1Qsf1WVKu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def transform_download_load(imgSize=224 , norm_mean= (0.5,0.5,0.5), norm_std = (0.5,0.5,0.5),dataset=torchvision.datasets.CIFAR10,batch_size=16): \n",
        "\n",
        "  transform_train = transforms.Compose([\n",
        "                                      transforms.RandomResizedCrop(299),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
        "  ])\n",
        "\n",
        "  transform_test = transforms.Compose([\n",
        "                                     transforms.RandomResizedCrop(299),\n",
        "                                     transforms.ToTensor(),\n",
        "                                     transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
        "  ])\n",
        "  train_set = dataset('./data',train=True,download=True,transform=transform_train)\n",
        "  test_set = dataset('./data',train=False,download=True,transform=transform_test)\n",
        "  trainloader = torch.utils.data.DataLoader(train_set,batch_size=batch_size,shuffle=True)\n",
        "  testloader = torch.utils.data.DataLoader(test_set,batch_size=batch_size,shuffle=False)\n",
        "\n",
        "  return trainloader, testloader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2aNjDtjGXzA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_initialize(model, pretain=True):\n",
        "   net = model(pretrained=True)\n",
        "   for param in net.parameters():\n",
        "     param.requires_grad = False\n",
        "   return net"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r79CWVX3K6AF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluation(dataloader, model):\n",
        "  total , correct = 0 , 0 \n",
        "  for data in dataloader: \n",
        "    inputs, labels = data \n",
        "    inputs, labels = inputs.to(device) , labels.to(device)\n",
        "    outputs  = model(inputs)\n",
        "    _ , pred = torch.max(outputs.data , 1 )\n",
        "    total += labels.size(0)\n",
        "    correct += (pred == labels).sum().item()\n",
        "  return 100 * (correct / total )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aI3l7l2vLgzw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def fit(function,lr,weight_decay,loss_fn,net,train_loader,test_loader,batch_size):\n",
        "  for i in range(len(lr)):\n",
        "    for j in range(len(weight_decay)):\n",
        "      for k in range(len(function)):\n",
        "        opt = function[k](net.parameters(),lr=lr[i], weight_decay=weight_decay[j])\n",
        "        loss_arr = []\n",
        "        loss_arr_epoch = []\n",
        "        max_epoch = 1 \n",
        "        n_iter = np.ceil(50000/batch_size)\n",
        "        print(function[k])\n",
        "        print(\"For weight decay : %f and For learning Rate : %f:\" % (weight_decay[j], lr[i]))\n",
        "        min_loss = 1000\n",
        "\n",
        "        for epoch in range(max_epoch):\n",
        "          for l , data in enumerate(train_loader,0):\n",
        "            inputs, labels = data \n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            opt.zero_grad()\n",
        "            outputs= net(inputs)\n",
        "            loss = loss_fn(outputs,labels)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            if min_loss > loss.item():\n",
        "              min_loss = loss.item()\n",
        "              best_model = copy.deepcopy(net.state_dict())\n",
        "              #print(\"Min Loss %0.2f\"% min_loss)\n",
        "            #if l % 100 == 0 : \n",
        "              #print(\"Epoch %d/%d, Loss : %0.2f\"  % (l, n_iter,loss.item()))\n",
        "            \n",
        "            del inputs, labels, outputs \n",
        "            torch.cuda.empty_cache()\n",
        "          loss_arr_epoch.append(loss.item())\n",
        "          net.load_state_dict(best_model)\n",
        "          print(\"Epoch %d/%d , Test Accuracy : %0.2f , Train Accuracy : %0.2f\" % (epoch, max_epoch, evaluation(test_loader,net), evaluation(train_loader,net)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEiZELoBXQgb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "1518d3c1-808a-43c2-b60d-23a7adc677c9"
      },
      "source": [
        "batch_size = 128 \n",
        "num_classes = 100\n",
        "trainloader , testloader = transform_download_load(imgSize=299, batch_size=batch_size,dataset=torchvision.datasets.CIFAR100)\n",
        "\n"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4l3hefR8HPKB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " \n",
        "squeezenet = models.squeezenet1_1(pretrained=True)\n",
        "for param in squeezenet.parameters():\n",
        "  param.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twNCrYhrIx0Z",
        "colab_type": "code",
        "outputId": "81cd9c4c-d333-4651-a24a-06d52867fc15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(squeezenet)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SqueezeNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (3): Fire(\n",
            "      (squeeze): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace=True)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace=True)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): Fire(\n",
            "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace=True)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace=True)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (6): Fire(\n",
            "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace=True)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace=True)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace=True)\n",
            "    )\n",
            "    (7): Fire(\n",
            "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace=True)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace=True)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace=True)\n",
            "    )\n",
            "    (8): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (9): Fire(\n",
            "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace=True)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace=True)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace=True)\n",
            "    )\n",
            "    (10): Fire(\n",
            "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace=True)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace=True)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace=True)\n",
            "    )\n",
            "    (11): Fire(\n",
            "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace=True)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace=True)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace=True)\n",
            "    )\n",
            "    (12): Fire(\n",
            "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace=True)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace=True)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Conv2d(512, 1000, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7hF6Z1gKM3S",
        "colab_type": "text"
      },
      "source": [
        "# Altering the aux and Fc layer to suit the CIFAR dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQppqPy6ovfj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "outputId": "61f0f4c6-f8b9-497e-8372-72cc09ba7e28"
      },
      "source": [
        "\n",
        "final_in_channels = squeezenet.classifier[1].in_channels\n",
        "squeezenet.classifier[1] = nn.Conv2d(final_in_channels,num_classes,kernel_size=(1,1),stride=(1,1))\n",
        "print(squeezenet.classifier)\n"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Dropout(p=0.5, inplace=False)\n",
            "  (1): Conv2d(512, 100, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (2): ReLU(inplace=True)\n",
            "  (3): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSaJi7GDJ546",
        "colab_type": "code",
        "outputId": "dabb5003-c357-474d-ecd9-859ff4ae40a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "for param in squeezenet.parameters():\n",
        "  if param.requires_grad:\n",
        "    print(param.shape)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([100, 512, 1, 1])\n",
            "torch.Size([100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6WaeksiLqXG",
        "colab_type": "text"
      },
      "source": [
        "#Training and evaluation of the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htNt7kygPEWS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "squeezenet = squeezenet.to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "opt = optim.SGD(squeezenet.parameters(), lr = 0.01)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "lr = [0.01]\n",
        "#lr = [0.1,0.01,0.001,0.0001]\n",
        "weight_decay = [0.0001]\n",
        "function = [optim.SGD, optim.Adam, optim.Adagrad, optim.RMSprop]\n",
        "fit(function=function,lr=lr,weight_decay=weight_decay,loss_fn=loss_fn,net=squeezenet,train_loader=trainloader,test_loader=testloader,batch_size=batch_size)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RD6aYH6MfO2V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "print(\"Epoch %d/%d , Test Accuracy : %0.2f , Train Accuracy : %0.2f\" % (0, 1, evaluation(testloader,squeezenet), evaluation(trainloader,squeezenet)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGPsx_UTPLnn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}